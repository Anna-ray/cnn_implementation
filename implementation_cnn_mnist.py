# -*- coding: utf-8 -*-
"""implementation CNN_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12h1Yy5Slc1I0aU8VgJUhTOn8OSRExboW

## Etape 1 - Importer et initialiser
"""

import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt
import sys,os
from importlib import reload
import pandas as pd

"""Verbosité durant l'entrainement : 0 = rien, 1 = barre de progression, 2 = une ligne par epoch"""

fit_verbosity = 1

"""## Step 2 - Retrieve data
MNIST est l'un des datasets les plus connus.
Disponible dans [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)
"""

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

#x_train = x_train.reshape(-1,28,28,1)
#x_test  = x_test.reshape(-1,28,28,1)

print("x_train : ",x_train.shape)
print("y_train : ",y_train.shape)
print("x_test  : ",x_test.shape)
print("y_test  : ",y_test.shape)

"""## Etape 3 - Préparation des données"""

print('Avant la normalisation : Min={}, max={}'.format(x_train.min(),x_train.max()))

xmax=x_train.max()
x_train = x_train / xmax
x_test  = x_test  / xmax

print('Après la normalisation  : Min={}, max={}'.format(x_train.min(),x_train.max()))

"""### Voir quelques images de MNIST"""

# plot first few images
for i in range(9):
	# define subplot
	plt.subplot(330 + 1 + i)
	# plot raw pixel data
	plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))
# show the figure
plt.show()

"""## Etape 4 - Créer un modèle
Avoir plus d'information sur : 
 - [Les optimiseurs](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)
 - [Les fonctions d'activation](https://www.tensorflow.org/api_docs/python/tf/keras/activations)
 - [Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses)
 - [Les métriques d'évaluation](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)
"""

model = keras.models.Sequential()

model.add( keras.layers.Input((28,28,1)) )

model.add( keras.layers.Conv2D(16, (3,3), activation='selu'))
model.add( keras.layers.MaxPooling2D((2,2)))
model.add( keras.layers.Dropout(0.2))

model.add( keras.layers.Conv2D(16, (3,3), activation='selu'))
model.add( keras.layers.MaxPooling2D((2,2)))
model.add( keras.layers.Dropout(0.2))

model.add( keras.layers.Flatten()) 
model.add( keras.layers.Dense(100, activation='selu'))
model.add( keras.layers.Dropout(0.5))

model.add( keras.layers.Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""## Etape 5 - Entrainer le modèle"""

batch_size  = 512
epochs      =  16

history = model.fit(  x_train, y_train,
                      batch_size      = batch_size,
                      epochs          = epochs,
                      verbose         = fit_verbosity,
                      validation_data = (x_test, y_test))

"""## Etape 6 - Evaluer le modèle

"""

score = model.evaluate(x_test, y_test, verbose=0)

print(f'Test loss     : {score[0]:4.4f}')
print(f'Test accuracy : {score[1]:4.4f}')

"""### 6.2 - Plot history"""

loss_train = history.history['loss']
loss_val = history.history['val_loss']
epochs = range(0,16)
plt.plot(epochs, loss_train, 'g', label='loss')
plt.plot(epochs, loss_val, 'b', label='val_loss')
plt.title('Erreurs')
plt.xlabel('Epochs')
plt.ylabel('Valeurs')
plt.legend()
plt.show()

loss_train = history.history['accuracy']
loss_val = history.history['val_accuracy']
epochs = range(0,16)
plt.plot(epochs, loss_train, 'g', label='accuracy')
plt.plot(epochs, loss_val, 'b', label='val_accuracy')
plt.title('Erreurs')
plt.xlabel('Epochs')
plt.ylabel('Valeurs')
plt.legend()
plt.show()

"""# 6.4 - Matrice de confusion

"""

y_sig = model.predict(x_test)
y_pred = np.argmax(y_sig, axis=-1)

from sklearn.metrics import confusion_matrix
import itertools

cm = confusion_matrix(y_test, y_pred)

import seaborn as sn
plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Prédite')
plt.ylabel('Correcte')